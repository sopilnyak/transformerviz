# Transformer visualization

This tool visualizes the attention heads in the Transformer model to help better understand its internals. Currently it supports three pre-trained models from the [transformers](https://github.com/huggingface/transformers) library: BERT, XLM and GPT-2. 

## Try it out

The demo is available at [http://transformerviz.eastus.cloudapp.azure.com/](http://transformerviz.eastus.cloudapp.azure.com/)

## References

[A Multiscale Visualization of Attention in the Transformer Model](https://arxiv.org/pdf/1906.05714.pdf)
